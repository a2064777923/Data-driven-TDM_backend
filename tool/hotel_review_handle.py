import json
import re
from collections import Counter, defaultdict

import nltk
from dask.array import negative
from nltk import pos_tag, word_tokenize
from nltk.corpus import stopwords
from textblob import TextBlob

def is_float(s):
    try:
        float(s)
        return True
    except ValueError:
        return False

def is_all_english(sentence):
    return bool(re.match(r'^[a-zA-Z\s]+$', sentence))

def clean_review(review):
    # å»æ‰æ— ç”¨çš„ä¿¡æ¯
    lines = review.strip().split('\n')
    #print("-------------------------original----------------------------------")
    #print(lines)
    del lines[0] #short cut
    commenter = lines.pop(0)
    region = lines.pop(0)
    room_level = lines.pop(0)
    room_night = lines.pop(0)
    members = lines.pop(0)
    score = 0
    comment_content = []
    for line in lines:
        if "There are no comments available for this review" in line:
            continue
        elif "Reviewers choice" in line or "Reviewed" in line:
            continue
        elif "Scored" in line:
            score = float(line.split(" ")[1])
        elif line.isdigit() or is_float(line):
            score = float(line)
        elif "Helpful" in line or "Not helpful" in line or "found this review helpful" in line:
            continue
        else:
            comment_content.append(line.strip())
    processed_result = {"commenter":commenter,"region":region,"room_level":room_level,"room_night":room_night,"members":members,"score":score,"comment_content":comment_content}
    print("---------------------------------------process----------------------------------------------------")
    return processed_result


def analyze_sentiment(review):
    blob = TextBlob(review)
    sentiment = blob.sentiment.polarity

    return sentiment


def extract_nouns(review):
    tokens = word_tokenize(review)
    tagged = pos_tag(tokens)
    nouns = [word for word, pos in tagged if pos in ['NN', 'NNS']] #'NNP', 'NNPS']]ä¸è¦å°ˆæœ‰åè©äº†
    return nouns

def remove_supersets(nouns):
    nouns = set(nouns)
    to_remove = set()

    for noun in nouns:
        for other in nouns:
            if noun != other and noun in other:
                # å¦‚æœ noun æ˜¯ other çš„å­é›†ä¸”äºŒè€…ä¸åŒï¼Œåˆ™ç§»é™¤è¾ƒé•¿çš„é‚£ä¸ª
                to_remove.add(other)

    return nouns - to_remove


if __name__ == '__main__':
    #nouns = {'adjacent', 'instruction', 'wait', 'æ•é ­', 'es', 'decade', 'spa', 'è¶…ç´šå¸‚å ´', 'kunnen', 'products', 'tranquilo', 'need', 't he', 'bÃ¥de', 'cash', 'ç«è»Šç«™', 'plug', 'å¹é«®å™¨', 'mehr', 'bit', 'rail', 'rochen', 'entrance', 'ê³µê°„', 'grÃ¼n', 'muf', 'und', 'milk', 'ç™¾è²¨', 'ææ€–', 'MRT', 'call', 'bra', 'wasn', 'policy', 'range', 'helt', 'specific', 'ä¾¿åˆ©åº—', 'ä¸€æ¬¡ä»˜æ¸…', 'åºŠ', 'club', 'face', 'æ³³æ± ', 'æœ‰é»æ“”å¿ƒ', 'je', 'dentro', 'í¸ë¦¬í•˜ê³ ', 'tiene', 'zwembad', 'å…¥ä½', 'sengen', 'tot', 'ä½å®¿', 'pool', 'rice', 'buurt', 'bij', 'ä½å®¢', 'job', 'wife', 'office', 'Bad', 'guards', 'æˆ¿é—´', 'geweldig', 'æ—¥æœ¬äºº', 'ideaal', 'tijdens', 'lobby', 'morning', 'back', 'pÃ¥', 'colours', 'bien', 'stay', 'æ²™ç™¼', 'walk', 'staff', 'hi', 'å’–å•¡', 'wise', 'æ¶ˆæ¯’æ¶²', 'lock', 'close', 'æ©Ÿå ´', 'sense', 'choice', 'pot', 'girl', 'aan', 'air', 'peice', 'å¿«é©', 'frÃ¤scht', 'mÃ©s', 'neck', 'slice', 'èˆ’æœ', 'nÃ¤ra', 'climatisation', 'locatie', 'æ°”å‘³', 'vi', 'well', 'check', 'é™¤è‡­åŠ‘', 'æœ‰ä¸€é»è¸å‘³', 'exit', 'Prima', 'èŠ±ç‘', 'é›»è¦–', 'Rien', 'sofa', 'pillow', 'æ»¡è¶³éœ€æ±‚', 'hygiÃ«nisch', 'hÃ¥rd', 'Check', 'midden', 'luxury', 'å¤§å ‚', 'å“æ´ª', 'æœ‰å•æœ‰ç­”', 'masayasæ§˜', 'å‘˜å·¥', 'mold', 'die', 'ğŸ˜œ', 'ï¼Œbig', 'å¯„å­˜è¡Œæ', 'æ¨“å±¤', 'trip', 'wir', 'fijn', 'å†·æ°£', 'druk', 'son', 'lift', 'cup', 'Lobby', 'gel', 'firm', 'Geweldig', 'å¾ˆæ£’', 'è·å“¡', 'couloirs', 'sehr', 'sorts', 'one', 'expectation', 'ceiling', 'ì„¼íŠ¸ëŸ´', 'cell', 'station', 'ammo', 'skills', 'bag', 'è£ä¿®', 'å‚¢ä¿±', 'í¸í•¨', 'fint', 'building', 'wassen', 'end', 'package', 'formatge', 'clinic', 'byen', 'fold', 'heaps', 'stool', 'STAff', 'line', 'luggage', 'exception', 'paar', 'penny', 'lÃ¤tt', 'work', 'groÃŸ', 'æ€»ä½“æ¥è¯´æŒºå¥½çš„', 'nvt', 'safe', 'rÃ­o', 'criticism', 'graden', 'ê±°ì—ìš”', 'go', 'æ€§ä»·æ¯”', 'vatbaar', 'use', 'æ°´', 'altijd', 'æœ‰ç¦®è²Œ', 'Pool', 'diligent', 'blunt', 'night', 'front', 'smelt', 'e.g', 'ï¼ï¼', 'tÃ¤glich', 'een', 'help', 'bridge', 'Connects', 'cross', 'light', 'ç‰¹å¤§æˆ¿', 'tv', 'molt', 'storage', 'vor', 'à¹€à¸‹à¸­à¸£à¹Œà¸§à¸´à¸•à¸„à¸§à¸£à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡à¹ƒà¸«à¹‰à¸¡à¸²à¸à¸à¸§à¹ˆà¸²à¸™à¸µà¹‰', 'twin', 'memory', 'finish', 'car', 'world', 'panel', 'à¸–à¸¹à¸à¹ƒà¸ˆà¸¡à¸²à¸', 'depan', 'toys', 'sum', 'vague', 'ä½“éªŒ', 'bay', 'smell', 'wifi', 'biscuits', 'Nice', 'deilig', 'ğŸ‘ğŸ‘ğŸ‘', 'gab', 'prospect', 'pickups', 'madrassen', 'spray', 'cost', 'ä¸€æ¬¡å°±å¤ ', 'sarapan', 'ride', 'kid', 'ç›´æ’­', 'Enjoy', 'à¹„à¸¡à¹ˆà¸¡à¸µà¸Ÿà¸´à¸•à¹à¸¥à¸°à¸ªà¸£à¸°à¸§à¹ˆà¸²à¸¢à¸™à¹‰à¸³à¹ƒà¸«à¹‰à¸šà¸£à¸´à¸à¸²à¸£à¹à¸¥à¸°à¸„à¸§à¸£à¸¡à¸µà¸„à¸™à¸¡à¸²à¸Šà¹ˆà¸§à¸¢à¸¥à¸¹à¸à¸„à¹‰à¸²à¸¢à¸à¸à¸£à¸°à¹€à¸›à¹‹à¸²à¸”à¹‰à¸§à¸¢', 'gifts', 'gigantische', 'å·®', 'æµ´å®¤', 'time', 'sentrum', 'Ğ´Ğ¾', 'ke', 'ein', 'è¨­æ–½', 'heisen', 'course', 'sÃ¤ng', 'à¸—à¹à¸²à¹€à¸¥à¹à¸¥à¸°à¸—à¸µà¹ˆà¸à¸±à¸à¸ªà¸°à¸­à¸²à¸”à¸¡à¸²à¸à¸à¸™à¸±à¸à¸‡à¸²à¸™à¸—à¸¸à¸à¸„à¸™à¸¡à¸²à¸£à¸¢à¸²à¸—à¸”à¸µà¸¡à¸²à¸', 'op', 'Car', 'cot', 'å°Šæ•¬', 'proof', 'maid', 'éŒ¢', 'Etage', 'fan', 'dinÃ¡mico', 'allt', 'seats', 'frukost', 'è²»äº‹å‡ºè²', 'éå¸¸å¥½', 'ä»·æ ¼', 'à¹‚à¸”à¸¢à¸£à¸§à¸¡à¸”à¸µà¸à¸™à¸±à¸à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸à¸¹à¸”à¸ˆà¸²à¹à¸¥à¸°à¹ƒà¸«à¹‰à¸„à¸§à¸²à¸¡à¸Šà¹ˆà¸§à¸¢à¹€à¸«à¸¥à¸·à¸­à¸”à¸µ', 'life', 'ä¸è¶³å¤ ç”¨', 'Pillows', 'ganz', 'æ•´é«”', 'pub', 'city', 'group', 'man', 'å‰å°', 'Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ğ»Ğ¸', 'OK', 've', 'link', 'åŠ è³¼', 'ç¦ç…™æˆ¿', 'dining', 'cinema', 'men', 'extras', 'å¯ä»¥æ¥å—', 'ë„ˆë¬´ë§Œì¡±ìŠ¤ëŸ¬ì›€', 'â˜¹ï¸', 'base', 'tiefe', 'æ—©é¤', 'bei', 'w.cheung', 'tai', 'seltsam', 'vÃ¦k', 'ç”ŸæœåŠè›‹ä¸è¶³', 'çª©å¿ƒä¹‹æ—…', 'photo', 'æ’è˜‡ä½', 'æœåŠ¡', 'dÃ­as', 'å•†å ´', 'gb', 'ê´€ê´‘ì§€ì™€', 'æˆ¿é–“', 'ç™¼éœ‰', 'vacation', 'le', 'é£¯åº—', 'peu', 'royal', 'case', 'é…’åº—', 'forhÃ¥nd', 'cockroach', 'ĞĞ¾Ğ¼ĞµÑ€Ğ°', 'seals', 'centrum', 'æ¯”è¼ƒèˆŠ', "l'amabilitat", 'èˆ’é€‚', 'é¦™æ¸¯', 'liquid', 'ì¢‹ê² ìŒ', 'para', 'å¥—é¤', 'Food', 'kong', 'on/off', 'noise', 'count', 'faltar', 'stort', 'å®¢äºº', 'buggy', 'vÃ¤nja', 'ğŸ˜€', 'kÃ¶p', 'war', 'typhoon', 'ha', 'monitor', 'mit', 'cycling', 'Man', 'usage', 'behulpzaam', 'voor', 'jg', 'amazing', 'ç©ºé–“', 'speedy', 'bed', 'sq', 'fÃ¶r', 'dust', 'Tv', 'right', 'ç‰©è¶…æ‰€å€¼', 'badrum', 'æœå‹™', 'tan', 'brush', 'till', 'praise', 'æœ‰é»æ—©', 'et', 'vÃ¦rt', 'tid', 'ä½ç½®', 'couldn', 'ç–«æƒ…', 'YYM', 'client', 'Meals', 'é£æ™¯', 'æ—©ä¸Š', 'pm', 'choonï¼Œ', 'noisy', 'å»å¹´', 'efficiency', 'dine', 'tin', 'vue', 'æ•´ä¿®', 'éƒ½å¾ˆå¥½', 'æ¸…æ½”', 'xiuping', 'ç¾ä¸­ä¸è¶³', 'king', 'riecht', 'à¸—à¸³à¹€à¸¥à¸ªà¸°à¸”à¸§à¸', 'towel', 'ğŸ˜Š', 'jacky', 'Staff', 'ç©ºè°ƒ', 'act', 'juga', 'si', 'ben', 'loan', 'school', 'åˆ¶å†·', 'Lack', 'quality', 'å‘³é“', 'min', 'ì í•©', 'tip', 'traffic', 'maar', 'function', 'deur', 'æˆ¿é—¨', 'å¸ç…™æˆ¿', 'fast', 'lunch', 'è£…ä¿®', 'plumb', 'å¦å¤–', 'rack', 'bin', 'flush', 'moulds', 'familie', 'gingen', 'pas', 'hour', 'è®¾æ–½', 'koffie', 'æ²³æ™¯', 'dim', 'bar', 'å®¶åº­', 'couch', 'aspect', 'æŠ¼é‡‘', 'ask', 'å¥¶ç“¶', 'å»æ‰€', 'vÃ¥ningar', 'trotzdem', 'fuk', 'upgrade', 'art', 'dit', 'van', 'voice', 'location', 'Ñ€Ğ°ÑĞ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ', 'gaf', 'point', 'wash', 'tussen', 'ì²­ê²°', 'soepel', 'chloorsmaak', 'meat', 'privacy', 'rigtig', 'plus', 'mÃ¥', 'ok', 'load', 'bulk', 'cabs', 'Ok', 'fee', 'iron', 'Xuan', 'é‚„ä¸éŒ¯', 'ä¸€èˆ¬', 'da', 'star', 'è“®è“¬é ­', 'åˆ†éš”', 'tub', 'ä¸‹é›¨', 'ä¸‹æ¬¡', 'å•†åœº', 'var', 'week', 'ppl', 'issue', 'disruption', 'muss', 'pÃºblic', 'Lifts', 'buchen', 'way', 'mall', 'groot', 'toen', 'Dear', 'drying', 'inn', 'æ´—æ‰‹é–“', 'rude', 'noice', 'Nil', 'swim', 'lys', 'ê°€ê¹ê³ ', 'alojaron', 'cold', 'klÃ¦r', 'æ¸¸æ³³é¦†', 'fault', 'fort', 'ideal', 'ons', 'å¬°å…’', 'year', 'gran', 'ì—†ì–´ìš”', 'ğŸ”¥', 'ä¸ä¼šå†é¸', 'auf', 'family', 'ì§€í•˜ì² ', 'fÃ¼r', 'adequaat', 'skin', 'ç’°å¢ƒ', 'cap', 'foot', 'drink', 'å¤–é¢', 'æ•´æ½”', 'la', 'arrival', 'von', 'mooi', 'hygiÃ«ne', 'Beds', 'tunnel', 'RengÃ¸rings', 'ist', 'éš”éŸ³', 'pricy', 'æ¯”åƒ¹æ€§', 'hub', 'cool', 'ruim', 'baby', 'å“¡å·¥', 'fruit', 'ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ«ãŒè¿‘ãã€éå¸¸ã«ä¾¿åˆ©', 'ç©ºæ°”', 'Efficient', 'kort', 'lot', 'å®¢æœ', 'search', 'äººå“¡', 'con', 'é§…', 'å®‰é™', 'ìˆ˜ì˜ì¥ì´í¬ê³ ', 'type', 'self', 'mtr', 'og', 'ut', 'ê±°ë¦¬ê°€ìˆìŒ', 'knuffels', 'å¯¬é—Š', 'litt', 'Yinï¼Œ', 'èˆ’é©', 'didn', 'hospitality', 'å«ç”Ÿ', 'ğŸ¤—', 'å°¾æˆ¿', 'nicht', 'eg', 'nurse', 'chengjin', 'av', 'TV', 'decor', 'stuff', 'sÃ¸de', 'speciellt', 'meal', 'bell', 'floor', 'value', 'N.A', 'journey', 'app', 'æ„Ÿè§‰ä¸é”™', 'ğŸ¥°ğŸ¥°ğŸ¥°ğŸ¥°ğŸ¥°ğŸ¥°', 'æ–·ç·šåš´é‡', 'æ™‚é–“', 'hygiene', 'obligatory', 'waar', 'æ–¹ä¾¿', 'soap', 'ã¨ã¦ã‚‚æº€è¶³', 'schoon', 'Location', 'food', 'mig', 'å¾ˆæ»¿æ„', 'ç¯å¢ƒ', 'cast', 'è', 'í˜¸í…”', 'facility', 'heat', 'rain', 'port', 'trÃ¨s', 'æº€è¶³ã—ã¾ã—ãŸï¼', 'à¹‚à¸”à¸¢à¸£à¸§à¸¡à¸à¸™à¸±à¸à¸‡à¸²à¸™à¸¡à¸²à¸£à¸¢à¸²à¸—à¸”à¸µà¹à¸¥à¸°à¹ƒà¸«à¹‰à¸„à¸§à¸²à¸¡à¸Šà¹ˆà¸§à¸¢à¹€à¸«à¸¥à¸·à¸­à¸”à¸µ', 'accident', 'nydelig', 'æ²¡æœ‰', 'MTR', 'å†‡', 'mum', 'inå¿«', 'park', 'samme', 'gehorig', 're', 'Noisy', 'que', 'speck', 'å¥èº«å®¤', 'zijn', 'wall', 'bus', 'multitude', 'arm', 'å˜ˆ', 'notice', 'draws', 'ç©ºèª¿', 'kan', 'hk', 'noe', 'Reception', 'fridge', 'sÃ¥', 'heeft', 'coz', 'kind', 'æµ´ç¼¸', 'ze', 'å¾ˆä¸éŒ¯', 'taxi', 'town', 'localisation', 'hebt', 'att', 'mood', 'æ‰“æƒ', 'kowloon', 'meaning', 'er', 'katie', 'åƒ¹æ ¼', 'ae', 'à¹à¸¡à¹ˆà¸šà¹‰à¸²à¸™à¸—à¹à¸²à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¸«à¹‰à¸­à¸‡à¹„à¸¡à¹ˆà¸ªà¸°à¸­à¸²à¸”à¹€à¸›à¹‡à¸™à¸šà¹‰à¸²à¸‡à¸„à¹‰à¸²à¸‡à¸•à¹‰à¸­à¸‡à¹ƒà¸«à¹‰à¸šà¸­à¸', 'åœ°é»', 'zwei', 'fumar', 'å¤±æœ›', 'gem', 'å¹²å‡ˆ', 'dusch', 'Lights', 'æ«ƒå°', 'flowing', 'Porion', 'suits', 'Simon', 'limpia', 'PERFECT', 'guys', 'æ’é ­', 'dino', 'yan', 'cans', 'gym', 'gripe'}
    #removed_nouns = remove_supersets(nouns)
    #print(removed_nouns)

    nltk.download("punkt")
    nltk.download('averaged_perceptron_tagger')
    with open("./resources/hotel_reviews.json", "r", encoding="utf-8") as file:
        # ä»æ–‡ä»¶ä¸­åŠ è½½JSONæ•°æ®
        comment_reviews = json.load(file)
    result = {}
    all_adjective = set()
    adjective_classify = {'positive': ['comfortable', 'Rewelacja', 'Excellent', 'Definitely recommend', 'waanzinnige ervaring', 'OK', 'Fantastyczne miejsce', 'Fajnie', 'Very Good', 'Decent stay', 'good value', 'Good', 'Great relaxation', 'excellent', 'excellent staffs', 'Happy', 'Odlican hotel', 'Wonderful', 'Super', 'Fair', 'Comfortable stay', 'Exceptional', 'Fantastic', 'Friendly staffs', 'Lovely cruise', 'udany weekend', 'Marvelous', 'Surprisingly good', 'Pleasant', 'Stupendo', 'very good'], 'negative': ['Bad', 'Very Poor', 'Poor', 'Disappointing']}

    all_adjective_counts = {}
    all_noun_classify ={}

    for hotel, reviews in comment_reviews.items():
        all_reviews = []
        all_nouns = {'adjacent', 'instruction', 'wait', 'æ•é ­', 'decade', 'spa', 'è¶…ç´šå¸‚å ´', 'kunnen', 'products', 'tranquilo', 'need', 'bÃ¥de', 'cash', 'ç«è»Šç«™', 'plug', 'å¹é«®å™¨', 'mehr', 'bit', 'rail', 'rochen', 'entrance', 'ê³µê°„', 'grÃ¼n', 'muf', 'und', 'milk', 'ç™¾è²¨', 'ææ€–', 'MRT', 'call', 'bra', 'wasn', 'policy', 'range', 'helt', 'specific', 'ä¾¿åˆ©åº—', 'ä¸€æ¬¡ä»˜æ¸…', 'åºŠ', 'club', 'face', 'æ³³æ± ', 'æœ‰é»æ“”å¿ƒ', 'je', 'dentro', 'í¸ë¦¬í•˜ê³ ', 'tiene', 'zwembad', 'å…¥ä½', 'sengen', 'tot', 'ä½å®¿', 'pool', 'rice', 'buurt', 'ä½å®¢', 'job', 'wife', 'office', 'Bad', 'guards', 'æˆ¿é—´', 'geweldig', 'æ—¥æœ¬äºº', 'ideaal', 'tijdens', 'lobby', 'morning', 'back',  'colours', 'bien', 'stay', 'æ²™ç™¼', 'walk', 'staff',  'å’–å•¡', 'wise', 'æ¶ˆæ¯’æ¶²', 'lock', 'close', 'æ©Ÿå ´', 'sense', 'choice', 'pot', 'girl', 'aan', 'air', 'peice', 'å¿«é©', 'frÃ¤scht', 'mÃ©s', 'neck', 'slice', 'èˆ’æœ', 'nÃ¤ra', 'climatisation', 'locatie', 'æ°”å‘³', 'well', 'check', 'é™¤è‡­åŠ‘', 'æœ‰ä¸€é»è¸å‘³', 'exit', 'Prima', 'èŠ±ç‘', 'é›»è¦–', 'Rien', 'sofa', 'pillow', 'æ»¡è¶³éœ€æ±‚', 'hygiÃ«nisch', 'hÃ¥rd', 'Check', 'midden', 'luxury', 'å¤§å ‚', 'å“æ´ª', 'æœ‰å•æœ‰ç­”', 'masayasæ§˜', 'å‘˜å·¥', 'mold', 'die', 'ğŸ˜œ', 'big', 'å¯„å­˜è¡Œæ', 'æ¨“å±¤', 'trip',  'fijn', 'å†·æ°£', 'druk', 'son', 'lift', 'cup', 'Lobby', 'gel', 'firm', 'Geweldig', 'å¾ˆæ£’', 'è·å“¡', 'couloirs', 'sehr', 'sorts', 'one', 'expectation', 'ceiling', 'ì„¼íŠ¸ëŸ´', 'cell', 'station', 'ammo', 'skills', 'bag', 'è£ä¿®', 'å‚¢ä¿±', 'í¸í•¨', 'fint', 'building', 'wassen', 'end', 'package', 'formatge', 'clinic', 'byen', 'fold', 'heaps', 'stool', 'STAff', 'line', 'luggage', 'exception', 'paar', 'penny', 'lÃ¤tt', 'work', 'groÃŸ', 'æ€»ä½“æ¥è¯´æŒºå¥½çš„', 'nvt', 'safe', 'rÃ­o', 'criticism', 'graden', 'ê±°ì—ìš”',  'æ€§ä»·æ¯”', 'vatbaar', 'use', 'æ°´', 'altijd', 'æœ‰ç¦®è²Œ', 'Pool', 'diligent', 'blunt', 'night', 'front', 'smelt',   'tÃ¤glich', 'help', 'bridge', 'Connects', 'cross', 'light', 'ç‰¹å¤§æˆ¿', 'tv', 'molt', 'storage', 'vor', 'à¹€à¸‹à¸­à¸£à¹Œà¸§à¸´à¸•à¸„à¸§à¸£à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡à¹ƒà¸«à¹‰à¸¡à¸²à¸à¸à¸§à¹ˆà¸²à¸™à¸µà¹‰', 'twin', 'memory', 'finish', 'car', 'world', 'panel', 'à¸–à¸¹à¸à¹ƒà¸ˆà¸¡à¸²à¸', 'depan', 'toys', 'sum', 'vague', 'ä½“éªŒ', 'bay', 'smell', 'wifi', 'biscuits', 'Nice', 'deilig', 'ğŸ‘ğŸ‘ğŸ‘', 'gab', 'prospect', 'pickups', 'madrassen', 'spray', 'cost', 'ä¸€æ¬¡å°±å¤ ', 'sarapan', 'ride', 'kid', 'ç›´æ’­', 'Enjoy', 'à¹„à¸¡à¹ˆà¸¡à¸µà¸Ÿà¸´à¸•à¹à¸¥à¸°à¸ªà¸£à¸°à¸§à¹ˆà¸²à¸¢à¸™à¹‰à¸³à¹ƒà¸«à¹‰à¸šà¸£à¸´à¸à¸²à¸£à¹à¸¥à¸°à¸„à¸§à¸£à¸¡à¸µà¸„à¸™à¸¡à¸²à¸Šà¹ˆà¸§à¸¢à¸¥à¸¹à¸à¸„à¹‰à¸²à¸¢à¸à¸à¸£à¸°à¹€à¸›à¹‹à¸²à¸”à¹‰à¸§à¸¢', 'gifts', 'gigantische', 'å·®', 'æµ´å®¤', 'time', 'sentrum', 'Ğ´Ğ¾', 'è¨­æ–½', 'heisen', 'course', 'sÃ¤ng', 'à¸—à¹à¸²à¹€à¸¥à¹à¸¥à¸°à¸—à¸µà¹ˆà¸à¸±à¸à¸ªà¸°à¸­à¸²à¸”à¸¡à¸²à¸à¸à¸™à¸±à¸à¸‡à¸²à¸™à¸—à¸¸à¸à¸„à¸™à¸¡à¸²à¸£à¸¢à¸²à¸—à¸”à¸µà¸¡à¸²à¸',  'Car', 'cot', 'proof', 'maid', 'éŒ¢', 'Etage', 'fan', 'dinÃ¡mico', 'seats', 'frukost', 'è²»äº‹å‡ºè²', 'éå¸¸å¥½', 'ä»·æ ¼', 'à¹‚à¸”à¸¢à¸£à¸§à¸¡à¸”à¸µà¸à¸™à¸±à¸à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸à¸¹à¸”à¸ˆà¸²à¹à¸¥à¸°à¹ƒà¸«à¹‰à¸„à¸§à¸²à¸¡à¸Šà¹ˆà¸§à¸¢à¹€à¸«à¸¥à¸·à¸­à¸”à¸µ', 'life', 'ä¸è¶³å¤ ç”¨', 'Pillows', 'ganz', 'æ•´é«”', 'pub', 'city', 'group', 'man', 'å‰å°', 'Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ğ»Ğ¸', 'OK',  'link', 'åŠ è³¼', 'ç¦ç…™æˆ¿', 'dining', 'cinema', 'men', 'extras', 'å¯ä»¥æ¥å—', 'ë„ˆë¬´ë§Œì¡±ìŠ¤ëŸ¬ì›€', 'â˜¹ï¸', 'base', 'tiefe', 'æ—©é¤', 'bei', 'w.cheung', 'tai', 'seltsam', 'vÃ¦k', 'ç”ŸæœåŠè›‹ä¸è¶³', 'çª©å¿ƒä¹‹æ—…', 'photo', 'æ’è˜‡ä½', 'æœåŠ¡', 'dÃ­as', 'å•†å ´', 'ê´€ê´‘ì§€ì™€', 'æˆ¿é–“', 'ç™¼éœ‰', 'vacation', 'é£¯åº—', 'peu', 'royal', 'case', 'é…’åº—', 'forhÃ¥nd', 'cockroach', 'ĞĞ¾Ğ¼ĞµÑ€Ğ°', 'seals', 'centrum', 'æ¯”è¼ƒèˆŠ', "l'amabilitat", 'èˆ’é€‚', 'é¦™æ¸¯', 'liquid', 'ì¢‹ê² ìŒ', 'para', 'å¥—é¤', 'Food', 'kong', 'on/off', 'noise', 'count', 'faltar', 'stort', 'å®¢äºº', 'buggy', 'vÃ¤nja', 'ğŸ˜€', 'kÃ¶p', 'war', 'typhoon', 'monitor', 'mit', 'cycling', 'Man', 'usage', 'behulpzaam', 'voor', 'amazing', 'ç©ºé–“', 'speedy', 'bed',  'fÃ¶r', 'dust', 'Tv', 'right', 'ç‰©è¶…æ‰€å€¼', 'badrum', 'æœå‹™', 'tan', 'brush', 'till', 'praise', 'æœ‰é»æ—©', 'vÃ¦rt', 'tid', 'ä½ç½®', 'couldn', 'ç–«æƒ…', 'YYM', 'client', 'Meals', 'é£æ™¯', 'æ—©ä¸Š', 'choonï¼Œ', 'noisy', 'å»å¹´', 'efficiency', 'dine', 'tin', 'vue', 'æ•´ä¿®', 'éƒ½å¾ˆå¥½', 'æ¸…æ½”', 'xiuping', 'ç¾ä¸­ä¸è¶³', 'king', 'riecht', 'à¸—à¸³à¹€à¸¥à¸ªà¸°à¸”à¸§à¸', 'towel', 'ğŸ˜Š', 'jacky', 'Staff', 'ç©ºè°ƒ', 'act', 'juga', 'si', 'ben', 'loan', 'school', 'åˆ¶å†·', 'Lack', 'quality', 'å‘³é“', 'min', 'ì í•©', 'tip', 'traffic', 'maar', 'function', 'deur', 'æˆ¿é—¨', 'å¸ç…™æˆ¿', 'fast', 'lunch', 'è£…ä¿®', 'plumb', 'å¦å¤–', 'rack', 'bin', 'flush', 'moulds', 'familie', 'gingen', 'pas', 'hour', 'è®¾æ–½', 'koffie', 'æ²³æ™¯', 'dim', 'bar', 'å®¶åº­', 'couch', 'aspect', 'æŠ¼é‡‘', 'ask', 'å¥¶ç“¶', 'å»æ‰€', 'vÃ¥ningar', 'trotzdem', 'fuk', 'upgrade', 'art', 'dit', 'van', 'voice', 'location', 'Ñ€Ğ°ÑĞ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ', 'gaf', 'point', 'wash', 'tussen', 'ì²­ê²°', 'soepel', 'chloorsmaak', 'meat', 'privacy', 'rigtig', 'plus', 'mÃ¥', 'ok', 'load', 'bulk', 'cabs', 'Ok', 'fee', 'iron', 'Xuan', 'é‚„ä¸éŒ¯', 'ä¸€èˆ¬', 'star', 'è“®è“¬é ­', 'åˆ†éš”', 'tub', 'ä¸‹é›¨', 'ä¸‹æ¬¡', 'å•†åœº', 'var', 'week', 'ppl', 'issue', 'disruption', 'muss', 'pÃºblic', 'Lifts', 'buchen', 'way', 'mall', 'groot', 'toen', 'Dear', 'drying', 'inn', 'æ´—æ‰‹é–“', 'rude', 'noice', 'Nil', 'swim', 'lys', 'ê°€ê¹ê³ ', 'alojaron', 'cold', 'klÃ¦r', 'æ¸¸æ³³é¦†', 'fault', 'fort', 'ideal', 'ons', 'å¬°å…’', 'year', 'gran', 'ì—†ì–´ìš”', 'ğŸ”¥', 'ä¸ä¼šå†é¸', 'auf', 'family', 'ì§€í•˜ì² ', 'fÃ¼r', 'adequaat', 'skin', 'ç’°å¢ƒ', 'cap', 'foot', 'drink', 'å¤–é¢', 'æ•´æ½”', 'la', 'arrival', 'von', 'mooi', 'hygiÃ«ne', 'Beds', 'tunnel', 'RengÃ¸rings', 'ist', 'éš”éŸ³', 'pricy', 'æ¯”åƒ¹æ€§', 'hub', 'cool', 'ruim', 'baby', 'å“¡å·¥', 'fruit', 'ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ«ãŒè¿‘ãã€éå¸¸ã«ä¾¿åˆ©', 'ç©ºæ°”', 'Efficient', 'kort', 'lot', 'å®¢æœ', 'search', 'äººå“¡', 'con', 'é§…', 'å®‰é™', 'ìˆ˜ì˜ì¥ì´í¬ê³ ', 'type', 'self', 'mtr', 'og', 'ut', 'ê±°ë¦¬ê°€ìˆìŒ', 'knuffels', 'å¯¬é—Š', 'Yinï¼Œ', 'èˆ’é©', 'didn', 'hospitality', 'å«ç”Ÿ', 'ğŸ¤—', 'å°¾æˆ¿', 'nicht',  'nurse', 'chengjin', 'av', 'TV', 'decor', 'stuff', 'sÃ¸de', 'speciellt', 'meal', 'bell', 'floor', 'value', 'journey', 'app', 'æ„Ÿè§‰ä¸é”™', 'ğŸ¥°ğŸ¥°ğŸ¥°ğŸ¥°ğŸ¥°ğŸ¥°', 'æ–·ç·šåš´é‡', 'æ™‚é–“', 'hygiene', 'obligatory', 'waar', 'æ–¹ä¾¿', 'soap', 'ã¨ã¦ã‚‚æº€è¶³', 'schoon', 'Location', 'food', 'mig', 'å¾ˆæ»¿æ„', 'ç¯å¢ƒ', 'cast', 'è', 'í˜¸í…”', 'facility', 'heat', 'rain', 'port', 'trÃ¨s', 'æº€è¶³ã—ã¾ã—ãŸï¼', 'à¹‚à¸”à¸¢à¸£à¸§à¸¡à¸à¸™à¸±à¸à¸‡à¸²à¸™à¸¡à¸²à¸£à¸¢à¸²à¸—à¸”à¸µà¹à¸¥à¸°à¹ƒà¸«à¹‰à¸„à¸§à¸²à¸¡à¸Šà¹ˆà¸§à¸¢à¹€à¸«à¸¥à¸·à¸­à¸”à¸µ', 'accident', 'nydelig', 'æ²¡æœ‰', 'MTR', 'å†‡', 'mum', 'inå¿«', 'park', 'samme', 'gehorig',  'Noisy', 'que', 'speck', 'å¥èº«å®¤', 'zijn', 'wall', 'bus', 'multitude', 'arm', 'å˜ˆ', 'notice', 'draws', 'ç©ºèª¿', 'kan', 'hk', 'noe', 'Reception', 'fridge',  'heeft', 'coz', 'kind', 'æµ´ç¼¸', 'ze', 'å¾ˆä¸éŒ¯', 'taxi', 'town', 'localisation', 'hebt', 'mood', 'æ‰“æƒ', 'kowloon', 'meaning',  'katie', 'åƒ¹æ ¼', 'à¹à¸¡à¹ˆà¸šà¹‰à¸²à¸™à¸—à¹à¸²à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¸«à¹‰à¸­à¸‡à¹„à¸¡à¹ˆà¸ªà¸°à¸­à¸²à¸”à¹€à¸›à¹‡à¸™à¸šà¹‰à¸²à¸‡à¸„à¹‰à¸²à¸‡à¸•à¹‰à¸­à¸‡à¹ƒà¸«à¹‰à¸šà¸­à¸', 'åœ°é»', 'zwei', 'fumar', 'å¤±æœ›', 'gem', 'å¹²å‡ˆ', 'dusch', 'Lights', 'æ«ƒå°', 'flowing', 'Porion', 'suits', 'Simon', 'limpia', 'PERFECT', 'guys', 'æ’é ­', 'dino', 'yan', 'cans', 'gym', 'gripe'}

        adjective_counts = defaultdict(lambda: {"count": 0, "senti": ""})
        reviews_related_nouns = defaultdict(lambda: [])


        for review in reviews:
            cleaned_review = clean_review(review)
            print(cleaned_review)
            if len(cleaned_review["comment_content"]) == 1 and is_all_english(cleaned_review["comment_content"][0]) and len(cleaned_review["comment_content"][0].split(" ")) <= 2:
                # all_adjective.add(cleaned_review["comment_content"][0])
                comment = cleaned_review["comment_content"][0]
                if comment in adjective_classify["positive"]:
                    adjective_counts[comment]["count"] += 1
                    adjective_counts[comment]["senti"] = "positive"
                    continue

                elif comment in adjective_classify["negative"]:
                    adjective_counts[comment]["count"] += 1
                    adjective_counts[comment]["senti"] = "negative"
                    continue

            if cleaned_review:
                for line in cleaned_review["comment_content"]:
                    recombine_review = {"comment": line, "senti": "positive",
                                        "info": {"commenter": cleaned_review["commenter"],
                                                 "region": cleaned_review["region"],
                                                 "room_level": cleaned_review["room_level"],
                                                 "room_night": cleaned_review["room_night"],
                                                 "members": cleaned_review["members"],
                                                 "score": cleaned_review["score"]}}

                    sentiment = analyze_sentiment(line)
                    if sentiment >= 0:
                        recombine_review["senti"] = "positive"
                        all_reviews.append(recombine_review)
                    else:
                        recombine_review["senti"] = "negative"
                        all_reviews.append(recombine_review)
                    """
                    extracted_nouns = extract_nouns(line)
                    for noun in extracted_nouns:
                        all_nouns.add(noun)
                    """

        # è½¬æ¢ä¸ºæ‰€éœ€æ ¼å¼
        adjective_comment_count = [{"name": adj, "count": count_info["count"], "senti": count_info["senti"]}
                                   for adj, count_info in adjective_counts.items()]

        print(adjective_comment_count)
        all_adjective_counts[hotel] = adjective_comment_count

        for noun in all_nouns:
            for review in all_reviews:
                if noun in review["comment"]:
                    reviews_related_nouns[noun].append(review)

        noun_comment_classify = [{"name": noun, "reviews": reviews} for noun, reviews in reviews_related_nouns.items()]

        print(noun_comment_classify)
        all_noun_classify[hotel] = noun_comment_classify

    with open("hotel_reviews_adjective.json", "w", encoding="utf-8") as f:
        json.dump(all_adjective_counts, f, ensure_ascii=False, indent=4)

    with open("hotel_reviews_noun.json", "w", encoding="utf-8") as f:
        json.dump(all_noun_classify, f, ensure_ascii=False, indent=4)
"""

    print(all_adjective)
    adjective_senti = {x:analyze_sentiment(x) for x in all_adjective}
    print(adjective_senti)
    adjective_classify = {"positive":[],"negative":[]}
    for adj in all_adjective:
        if adjective_senti[adj] >= 0:
            adjective_classify["positive"].append(adj)
        else:
            adjective_classify["negative"].append(adj)

    print(adjective_classify)

            if cleaned_review:
                sentiment = analyze_sentiment(cleaned_review)
                all_reviews.append({'review': cleaned_review, 'sentiment': sentiment})
                nouns = extract_nouns(cleaned_review)
                all_nouns.extend(nouns)
    
        # ç»Ÿè®¡åè¯
        noun_counts = Counter(all_nouns).most_common(10)
        noun_list = [noun for noun, count in noun_counts]

        # ç”Ÿæˆæœ€ç»ˆ JSON æ•°æ®ç»“æ„
        result[hotel] = {
            'nouns': noun_list,
            'reviews': all_reviews
        }
        # è¾“å‡ºç»“æœ
    result_json = json.dumps(result, ensure_ascii=False, indent=2)
    print(result_json)
"""
